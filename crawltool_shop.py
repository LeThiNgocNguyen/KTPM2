import time
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

def setup_driver():
    """Kh·ªüi t·∫°o tr√¨nh duy·ªát Chrome v·ªõi Selenium"""
    options = Options()
    options.add_argument("--headless")  # Ch·∫°y kh√¥ng hi·ªÉn th·ªã giao di·ªán
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("start-maximized")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def crawl_shopee_products(search_keyword, max_pages=3):
    """Crawl danh s√°ch s·∫£n ph·∫©m tr√™n Shopee theo t·ª´ kh√≥a t√¨m ki·∫øm"""
    driver = setup_driver()
    products = []
    
    for page in range(max_pages):
        url = f"https://shopee.vn/search?keyword={search_keyword}&page={page}"
        print(f" ƒêang crawl trang {page + 1}: {url}")
        driver.get(url)
        time.sleep(5)  # Ch·ªù trang t·∫£i xong

        try:
            # Ch·ªù c√°c s·∫£n ph·∫©m t·∫£i xong
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.shopee-search-item-result__item"))
            )

            # L·∫•y HTML c·ªßa trang v√† ph√¢n t√≠ch v·ªõi BeautifulSoup
            soup = BeautifulSoup(driver.page_source, "html.parser")
            items = soup.select("div.shopee-search-item-result__item")

            for item in items:
                try:
                    # L·∫•y t√™n s·∫£n ph·∫©m
                    name = item.select_one(".Cve6sh").text.strip()

                    # L·∫•y gi√° s·∫£n ph·∫©m
                    price = item.select_one(".kJjFOd").text.strip()

                    # L·∫•y s·ªë l∆∞·ª£ng ƒë√£ b√°n
                    sold = item.select_one(".r6HknA")
                    sold = sold.text.strip() if sold else "Kh√¥ng c√≥ d·ªØ li·ªáu"

                    # L·∫•y ƒë√°nh gi√°
                    rating = item.select_one(".shopee-rating-stars__stars")
                    rating = len(rating.find_all("div", class_="shopee-rating-stars__star-wrapper")) if rating else "Kh√¥ng c√≥ ƒë√°nh gi√°"

                    # L·∫•y link s·∫£n ph·∫©m
                    link_tag = item.select_one("a")
                    link = "https://shopee.vn" + link_tag["href"] if link_tag else "Kh√¥ng c√≥ link"

                    # Th√™m v√†o danh s√°ch
                    products.append({
                        "T√™n s·∫£n ph·∫©m": name,
                        "Gi√°": price,
                        "S·ªë l∆∞·ª£ng ƒë√£ b√°n": sold,
                        "ƒê√°nh gi√°": rating,
                        "Link": link
                    })
                except Exception as e:
                    print(f" L·ªói khi l·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m: {e}")

        except Exception as e:
            print(f" L·ªói khi t·∫£i trang: {e}")

    driver.quit()

    # L∆∞u v√†o file CSV
    df = pd.DataFrame(products)
    df.to_csv("shopee_products.csv", index=False, encoding="utf-8-sig")

    print(f" ƒê√£ l∆∞u {len(products)} s·∫£n ph·∫©m v√†o file shopee_products.csv")
    return products

# üõí Nh·∫≠p t·ª´ kh√≥a c·∫ßn t√¨m ki·∫øm tr√™n Shopee
search_keyword = "tai nghe bluetooth"
shopee_products = crawl_shopee_products(search_keyword, max_pages=3)
